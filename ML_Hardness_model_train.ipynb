{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c8e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from xgboost import XGBRegressor\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03848c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBoost(X_train, X_test, y_train, y_test, X_predict, y_predict, fetures, loop, testindex):\n",
    "    Xgb = XGBRegressor()\n",
    "    \n",
    "    #best parameter finding using GridsearchCV\n",
    "    parameters = [\n",
    "        {'n_estimators': [20,50,70], 'max_depth':[3,4,5,7,10]}]\n",
    "    clf1 = GridSearchCV(Xgb, parameters, scoring='neg_mean_squared_error', cv=5)\n",
    "    clf1.fit(X_train, y_train)\n",
    "    param = clf1.best_params_\n",
    "    #print params\n",
    "    svr1 = XGBRegressor(n_estimators=param.get(\"n_estimators\"), max_depth=param.get(\"max_depth\"))\n",
    "    svr1.fit(X_train,y_train)\n",
    "    \n",
    "    y_pred=svr1.predict(X_test)\n",
    "    y_train_pred=svr1.predict(X_train)\n",
    "\n",
    "\n",
    "    dftrainname=\"%d_XGB_train.csv\"%(loop)\n",
    "    dftestname=\"%d_XGB_test.csv\"%(loop)\n",
    "\n",
    "    result_train_df=pd.DataFrame()\n",
    "    result_train_df[\"y_train\"]=y_train\n",
    "    result_train_df[\"y_train_pred\"]=list(y_train_pred.reshape(1,-1)[0])\n",
    "    \n",
    "    \n",
    "    result_test_df=pd.DataFrame()\n",
    "    result_test_df[\"y_test\"]=y_test\n",
    "    result_test_df[\"y_pred\"]=list(y_pred.reshape(1,-1)[0])\n",
    "    #result_test_df[\"Index\"]=testindex\n",
    "    result_train_df.to_csv(\"./%s\"%(dftrainname),index=False)\n",
    "    result_test_df.to_csv(\"./%s\"%(dftestname),index=False)\n",
    " \n",
    "    dfpredictname=\"%d_XGB_predict.csv\"%(loop)\n",
    "    y_predict_predict=svr1.predict(X_predict) \n",
    "    result_predict_df=pd.DataFrame()\n",
    "    #result_test_df[\"y_predict\"]=y_predict\n",
    "    result_predict_df[\"Index\"]=testindex\n",
    "    #result_test_df[\"Index\"]=testindex\n",
    "    result_predict_df[\"y_predict_predict\"]=list(y_predict_predict.reshape(1,-1)[0])\n",
    "    result_predict_df.to_csv(\"./%s\"%(dfpredictname),index=False)\n",
    "\n",
    "\n",
    "    train_score = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    test_r2=r2_score(y_test, y_pred)\n",
    "    train_r2=r2_score(y_train, y_train_pred)\n",
    "\n",
    "    train_mae=mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae=mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    joblib.dump(svr1,'%s_XGB_all.model'%(loop))\n",
    "\n",
    "    print(\"XGB\",train_r2 ,test_r2, train_score, test_score, train_mae, test_mae)\n",
    "    return train_r2, test_r2, train_score, test_score, train_mae, test_mae \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da4e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loops(num=10):    \n",
    "    #warnings.simplefilter('ignore')\n",
    "    rbf_array=[]\n",
    "    linear_array=[]\n",
    "    rf_array=[]\n",
    "    XGB_array=[]\n",
    "    loopindex=[]\n",
    "\n",
    "    for loop in range(1,num+1):\n",
    "        print(\"loop %d... \" %(loop))\n",
    "        data=pd.read_csv(r\"./H111.csv\")\n",
    "        testdata=pd.read_csv(r\"./H3876_Hypothetical.csv\")\n",
    "       \n",
    "        data = shuffle(data)\n",
    "\n",
    "        df_corr=data.corr()\n",
    "        df_corr.to_csv(r\"df_corr.csv\")\n",
    "\n",
    "        \n",
    "        data.drop([\"Index\"],axis=1,inplace=True)\n",
    "        \n",
    "        #print(\"Testdata Index\")\n",
    "        testindex=testdata[\"Index\"] ####################\n",
    "        #print(testindex)\n",
    "        testdata.drop([\"Index\"],axis=1,inplace=True)\n",
    "\n",
    "        y=data[\"Hv30\"]\n",
    "        X=data.drop(\"Hv30\",axis=1)\n",
    "        #y_test=testdata[\"Hv30\"]\n",
    "        #X_test=testdata.drop(\"Hv30\",axis=1)\n",
    "\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2)\n",
    "        #print(y_train)\n",
    "        std=MinMaxScaler()\n",
    "        X_train=std.fit_transform(X_train)\n",
    "        \n",
    "        X_test=std.transform(X_test) #STANDARDISING test inputs\n",
    "        \n",
    "        y_predict=testdata[\"Hv30\"]\n",
    "        X_predict=testdata.drop(\"Hv30\",axis=1)\n",
    "                                                #Standardize the values\n",
    "        X_predict=std.transform(X_predict)\n",
    "\n",
    "        features = list(X.columns)\n",
    "\n",
    "\n",
    "        loopindex.append(int(loop))\n",
    "        \n",
    "\n",
    "        XGB_record=[]\n",
    "        XGBflisttmp=list(XGBoost(X_train, X_test, y_train, y_test, X_predict, y_predict, features, loop, testindex))\n",
    "        XGB_record.extend(rflisttmp)\n",
    "        XGB_array.append(XGB_record)\n",
    "\n",
    "    \n",
    "    XGB_array_result=np.array(XGB_array)\n",
    "    XGB_array_mean=[\"mean_XGB\"]\n",
    "    XGB_array_mean.extend(list(np.mean(XGB_array_result, axis=0)))\n",
    "    XGB_array_mean.extend([\"NAN\", \"NAN\"])\n",
    "    XGB_array_std=[\"std_rf\"]\n",
    "    XGB_array_std.extend(list(np.std(XGB_array_result, axis=0)))\n",
    "    XGB_array_std.extend([\"NAN\", \"NAN\"])\n",
    "    XGB_array_result_6=XGB_array_result[:,1]\n",
    "    XGB_test_mae_mean=np.mean(XGB_array_result, axis=0)[1]\n",
    "    loopindex_array=np.array(loopindex).reshape(-1,1)\n",
    "    loopindex_array.dtype=int\n",
    "    error_XGB=XGB_array_result_6.reshape(-1,1) - XGB_test_mae_mean.reshape(-1,1)\n",
    "    error_XGB_absolute=np.absolute(error_XGB)\n",
    "    XGB_data_all=np.concatenate((loopindex_array,XGB_array_result, error_XGB_absolute), axis=1)\n",
    "    XGB_data_all_sort=np.concatenate((XGB_data_all[np.lexsort(XGB_data_all.T)],loopindex_array), axis=1)\n",
    "    title_XGB=[\"XGB_loop\" ,\"XGB_train_r2\", \"XGB_test_r2\", \"XGB_train_rmse\", \"XGB_test_rmse\", \"XGB_train_mae\", \"XGB_test_mae\", \"XGB_mae_error\", \"XGB_mae_error_index\"]\n",
    "    XGB_data_mean_std=np.concatenate((np.array([title_XGB]) ,XGB_data_all_sort, np.array([XGB_array_mean]), np.array([XGB_array_std])), axis=0)\n",
    "\n",
    "   \n",
    "    XGB=np.concatenate((XGB_data_mean_std), axis=0)\n",
    "\n",
    "    columns=[\"loop\" ,\"train_r2\", \"test_r2\", \"train_rmse\", \"test_rmse\", \"train_mae\", \"test_mae\", \"mae_error\", \"mae_error_index\"]\n",
    "    scoreing=pd.DataFrame(XGB, columns=columns)\n",
    "    scoreing.to_csv(r\"./scores.csv\", index=False)\n",
    "\n",
    "    np.set_printoptions(precision=5)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    loops(10)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
